{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211ebede",
   "metadata": {},
   "source": [
    "# 🚀 AdaBoost Hyperparameters\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 **Core Hyperparameters**\n",
    "\n",
    "### 🔢 **n_estimators** → Number of Weak Learners\n",
    "```\n",
    "📌 Default: 50  |  🎯 Range: 10-500+  |  💡 Start: 50-100\n",
    "```\n",
    "- Controls total sequential weak learners\n",
    "- ⬆️ More estimators = Better performance + Overfitting risk\n",
    "- 🎛️ Increase if underfitting detected\n",
    "\n",
    "### ⚡ **learning_rate** → Shrinkage Factor  \n",
    "```\n",
    "📌 Default: 1.0  |  🎯 Range: 0.01-2.0  |  💡 Sweet spot: 0.1-1.0\n",
    "```\n",
    "- Controls each weak learner's contribution\n",
    "- ⬇️ Lower rate = Conservative learning + Need more estimators\n",
    "- ⚖️ **Trade-off**: learning_rate ↓ ⟷ n_estimators ↑\n",
    "\n",
    "### 🌳 **base_estimator** → Weak Learner Choice\n",
    "```\n",
    "📌 Default: Decision Stump (max_depth=1)\n",
    "🔧 Key param: max_depth (1-3 typical)\n",
    "```\n",
    "- Usually DecisionTreeClassifier\n",
    "- Keep weak! (stumps work best)\n",
    "\n",
    "### 🎭 **algorithm** → Boosting Type\n",
    "```\n",
    "• SAMME.R (default) → Real AdaBoost, uses probabilities ⭐\n",
    "• SAMME → Discrete AdaBoost, classification only\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 **Quick Tuning Guide**\n",
    "\n",
    "### 🔍 **Grid Search Template**\n",
    "```python\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.5, 1.0],\n",
    "    'base_estimator__max_depth': [1, 2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6729a436",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
