{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb170cb",
   "metadata": {},
   "source": [
    "# üéØ **Gradient Descent: A Comprehensive Guide**\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ **Table of Contents**\n",
    "\n",
    "1. [Introduction & Intuition](#introduction--intuition)\n",
    "2. [Mathematical Foundation](#mathematical-foundation)\n",
    "3. [Types of Gradient Descent](#types-of-gradient-descent)\n",
    "4. [Learning Rate & Convergence](#learning-rate--convergence)\n",
    "5. [Advanced Optimization Algorithms](#advanced-optimization-algorithms)\n",
    "6. [Gradient Descent in Neural Networks](#gradient-descent-in-neural-networks)\n",
    "7. [Practical Implementation](#practical-implementation)\n",
    "8. [Common Challenges & Solutions](#common-challenges--solutions)\n",
    "9. [Applications & Examples](#applications--examples)\n",
    "10. [Best Practices](#best-practices)\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ **Introduction & Intuition**\n",
    "\n",
    "### **What is Gradient Descent?**\n",
    "\n",
    "Gradient descent is an **iterative optimization algorithm** used to find the minimum of a function. Imagine you're standing on a mountain and want to reach the lowest point (valley). Gradient descent is like taking steps in the direction of the steepest descent until you reach the bottom.\n",
    "\n",
    "### **Core Concept**\n",
    "\n",
    "The algorithm works by:\n",
    "- üîç **Computing the gradient** (slope) of the cost function\n",
    "- üèÉ‚Äç‚ôÇÔ∏è **Taking a step** in the opposite direction of the gradient\n",
    "- üîÑ **Repeating** until convergence\n",
    "\n",
    "### **Mathematical Intuition**\n",
    "\n",
    "For a function $f(x)$, the gradient $\\nabla f(x)$ points in the direction of **steepest ascent**. To minimize the function, we move in the **opposite direction**:\n",
    "\n",
    "$$\\boxed{x_{new} = x_{old} - \\alpha \\nabla f(x_{old})}$$\n",
    "\n",
    "Where:\n",
    "- $\\alpha$ is the **learning rate** (step size)\n",
    "- $\\nabla f(x)$ is the **gradient** of the function\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ **Mathematical Foundation**\n",
    "\n",
    "### **Single Variable Case**\n",
    "\n",
    "For a function $f(x)$ of one variable:\n",
    "\n",
    "$$\\boxed{x_{n+1} = x_n - \\alpha \\frac{df}{dx}\\bigg|_{x=x_n}}$$\n",
    "\n",
    "**Example:** Minimize $f(x) = x^2$\n",
    "\n",
    "- Gradient: $\\frac{df}{dx} = 2x$\n",
    "- Update rule: $x_{n+1} = x_n - 2\\alpha x_n = x_n(1 - 2\\alpha)$\n",
    "\n",
    "### **Multivariable Case**\n",
    "\n",
    "For a function $f(\\mathbf{x})$ where $\\mathbf{x} = [x_1, x_2, \\ldots, x_n]^T$:\n",
    "\n",
    "$$\\boxed{\\mathbf{x}_{n+1} = \\mathbf{x}_n - \\alpha \\nabla f(\\mathbf{x}_n)}$$\n",
    "\n",
    "Where the gradient is:\n",
    "\n",
    "$$\\nabla f(\\mathbf{x}) = \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial x_1} \\\\\n",
    "\\frac{\\partial f}{\\partial x_2} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial x_n}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "### **Linear Regression Example**\n",
    "\n",
    "For linear regression with cost function:\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "Where $h_\\theta(x) = \\theta_0 + \\theta_1 x$\n",
    "\n",
    "The gradients are:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\theta_0} = \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})$$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\theta_1} = \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x^{(i)}$$\n",
    "\n",
    "Update rules:\n",
    "\n",
    "$$\\boxed{\\theta_0 := \\theta_0 - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})}$$\n",
    "\n",
    "$$\\boxed{\\theta_1 := \\theta_1 - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x^{(i)}}$$\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ **Types of Gradient Descent**\n",
    "\n",
    "### **1. Batch Gradient Descent (BGD)**\n",
    "\n",
    "Uses the **entire dataset** to compute gradients:\n",
    "\n",
    "$$\\boxed{\\theta_{j} := \\theta_{j} - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} \\frac{\\partial}{\\partial \\theta_j} J(\\theta)}$$\n",
    "\n",
    "**Characteristics:**\n",
    "- ‚úÖ **Stable convergence** to global minimum (for convex functions)\n",
    "- ‚úÖ **Smooth gradient updates**\n",
    "- ‚ùå **Computationally expensive** for large datasets\n",
    "- ‚ùå **Slow** for big data\n",
    "\n",
    "### **2. Stochastic Gradient Descent (SGD)**\n",
    "\n",
    "Uses **one sample** at a time:\n",
    "\n",
    "$$\\boxed{\\theta_{j} := \\theta_{j} - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta; x^{(i)}, y^{(i)})}$$\n",
    "\n",
    "**Characteristics:**\n",
    "- ‚úÖ **Fast** for large datasets\n",
    "- ‚úÖ **Memory efficient**\n",
    "- ‚úÖ Can **escape local minima** due to noise\n",
    "- ‚ùå **Noisy convergence**\n",
    "- ‚ùå May **oscillate** around minimum\n",
    "\n",
    "### **3. Mini-Batch Gradient Descent**\n",
    "\n",
    "Uses **small batches** of data:\n",
    "\n",
    "$$\\boxed{\\theta_{j} := \\theta_{j} - \\alpha \\frac{1}{b} \\sum_{i=k}^{k+b-1} \\frac{\\partial}{\\partial \\theta_j} J(\\theta; x^{(i)}, y^{(i)})}$$\n",
    "\n",
    "Where $b$ is the batch size.\n",
    "\n",
    "**Characteristics:**\n",
    "- ‚úÖ **Balance** between BGD and SGD\n",
    "- ‚úÖ **Vectorized operations** possible\n",
    "- ‚úÖ **Stable** yet **efficient**\n",
    "- ‚úÖ **Most commonly used** in practice\n",
    "\n",
    "### **Comparison Table**\n",
    "\n",
    "| Method | Batch Size | Speed | Memory | Convergence | Noise |\n",
    "|--------|------------|-------|---------|-------------|-------|\n",
    "| **BGD** | Full dataset | Slow | High | Smooth | Low |\n",
    "| **SGD** | 1 | Fast | Low | Noisy | High |\n",
    "| **Mini-batch** | 32-512 | Medium | Medium | Balanced | Medium |\n",
    "\n",
    "---\n",
    "\n",
    "## üìä **Learning Rate & Convergence**\n",
    "\n",
    "### **Learning Rate ($\\alpha$)**\n",
    "\n",
    "The learning rate controls the **step size** in gradient descent:\n",
    "\n",
    "$$\\boxed{\\text{New position} = \\text{Current position} - \\alpha \\times \\text{Gradient}}$$\n",
    "\n",
    "### **Effect of Learning Rate**\n",
    "\n",
    "#### **Too Small ($\\alpha$ too small)**\n",
    "- ‚úÖ **Stable convergence**\n",
    "- ‚ùå **Very slow** convergence\n",
    "- ‚ùå May get **stuck** in plateaus\n",
    "\n",
    "#### **Too Large ($\\alpha$ too large)**\n",
    "- ‚ùå **Overshooting** the minimum\n",
    "- ‚ùå **Divergence** or oscillation\n",
    "- ‚ùå **Unstable** behavior\n",
    "\n",
    "#### **Just Right ($\\alpha$ optimal)**\n",
    "- ‚úÖ **Fast convergence**\n",
    "- ‚úÖ **Stable** behavior\n",
    "- ‚úÖ **Efficient** optimization\n",
    "\n",
    "### **Learning Rate Schedules**\n",
    "\n",
    "#### **1. Constant Learning Rate**\n",
    "$$\\alpha_t = \\alpha_0$$\n",
    "\n",
    "#### **2. Time-Based Decay**\n",
    "$$\\alpha_t = \\frac{\\alpha_0}{1 + \\text{decay} \\times t}$$\n",
    "\n",
    "#### **3. Step Decay**\n",
    "$$\n",
    "\\alpha_t = \\alpha_0 \\times \\text{drop}^{\\left\\lfloor \\frac{t}{\\text{epochs\\_drop}} \\right\\rfloor}\n",
    "$$\n",
    "\n",
    "\n",
    "#### **4. Exponential Decay**\n",
    "$$\\alpha_t = \\alpha_0 \\times e^{-\\text{decay} \\times t}$$\n",
    "\n",
    "#### **5. Adaptive Methods**\n",
    "- **AdaGrad:** $\\alpha_t = \\frac{\\alpha_0}{\\sqrt{G_t + \\epsilon}}$\n",
    "- **RMSprop:** $\\alpha_t = \\frac{\\alpha_0}{\\sqrt{v_t + \\epsilon}}$\n",
    "- **Adam:** Combines momentum and adaptive learning rates\n",
    "\n",
    "### **Convergence Criteria**\n",
    "\n",
    "#### **1. Gradient Magnitude**\n",
    "Stop when: $\\|\\nabla f(\\mathbf{x})\\| < \\epsilon$\n",
    "\n",
    "#### **2. Function Value Change**\n",
    "Stop when: $|f(\\mathbf{x}_{t+1}) - f(\\mathbf{x}_t)| < \\epsilon$\n",
    "\n",
    "#### **3. Parameter Change**\n",
    "Stop when: $\\|\\mathbf{x}_{t+1} - \\mathbf{x}_t\\| < \\epsilon$\n",
    "\n",
    "#### **4. Maximum Iterations**\n",
    "Stop after a fixed number of iterations\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ **Advanced Optimization Algorithms**\n",
    "\n",
    "### **1. Momentum**\n",
    "\n",
    "Adds a **momentum term** to accelerate convergence:\n",
    "\n",
    "$$\\boxed{\\begin{align}\n",
    "v_t &= \\beta v_{t-1} + (1-\\beta) \\nabla f(\\theta_{t-1}) \\\\\n",
    "\\theta_t &= \\theta_{t-1} - \\alpha v_t\n",
    "\\end{align}}$$\n",
    "\n",
    "Where:\n",
    "- $v_t$ is the **velocity** (momentum)\n",
    "- $\\beta$ is the **momentum coefficient** (typically 0.9)\n",
    "\n",
    "**Benefits:**\n",
    "- üöÄ **Faster convergence**\n",
    "- üéØ **Smoother updates**\n",
    "- üèÉ‚Äç‚ôÇÔ∏è **Helps escape** local minima\n",
    "\n",
    "### **2. Nesterov Accelerated Gradient (NAG)**\n",
    "\n",
    "**Lookahead** momentum:\n",
    "\n",
    "$$\\boxed{\\begin{align}\n",
    "v_t &= \\beta v_{t-1} + \\alpha \\nabla f(\\theta_{t-1} - \\beta v_{t-1}) \\\\\n",
    "\\theta_t &= \\theta_{t-1} - v_t\n",
    "\\end{align}}$$\n",
    "\n",
    "### **3. AdaGrad (Adaptive Gradient)**\n",
    "\n",
    "Adapts learning rate based on **historical gradients**:\n",
    "\n",
    "$$\\boxed{\\begin{align}\n",
    "G_t &= G_{t-1} + (\\nabla f(\\theta_{t-1}))^2 \\\\\n",
    "\\theta_t &= \\theta_{t-1} - \\frac{\\alpha}{\\sqrt{G_t + \\epsilon}} \\nabla f(\\theta_{t-1})\n",
    "\\end{align}}$$\n",
    "\n",
    "**Problem:** Learning rate **decreases too aggressively**\n",
    "\n",
    "### **4. RMSprop**\n",
    "\n",
    "Fixes AdaGrad's aggressive learning rate decay:\n",
    "\n",
    "$$\\boxed{\\begin{align}\n",
    "v_t &= \\beta v_{t-1} + (1-\\beta) (\\nabla f(\\theta_{t-1}))^2 \\\\\n",
    "\\theta_t &= \\theta_{t-1} - \\frac{\\alpha}{\\sqrt{v_t + \\epsilon}} \\nabla f(\\theta_{t-1})\n",
    "\\end{align}}$$\n",
    "\n",
    "### **5. Adam (Adaptive Moment Estimation)**\n",
    "\n",
    "Combines **momentum** and **adaptive learning rates**:\n",
    "\n",
    "$$\\boxed{\\begin{align}\n",
    "m_t &= \\beta_1 m_{t-1} + (1-\\beta_1) \\nabla f(\\theta_{t-1}) \\\\\n",
    "v_t &= \\beta_2 v_{t-1} + (1-\\beta_2) (\\nabla f(\\theta_{t-1}))^2 \\\\\n",
    "\\hat{m}_t &= \\frac{m_t}{1-\\beta_1^t} \\\\\n",
    "\\hat{v}_t &= \\frac{v_t}{1-\\beta_2^t} \\\\\n",
    "\\theta_t &= \\theta_{t-1} - \\frac{\\alpha}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t\n",
    "\\end{align}}$$\n",
    "\n",
    "**Default hyperparameters:**\n",
    "- $\\alpha = 0.001$\n",
    "- $\\beta_1 = 0.9$\n",
    "- $\\beta_2 = 0.999$\n",
    "- $\\epsilon = 10^{-8}$\n",
    "\n",
    "### **6. AdamW**\n",
    "\n",
    "Adam with **weight decay**:\n",
    "\n",
    "$$\\boxed{\\theta_t = \\theta_{t-1} - \\alpha \\left( \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} + \\lambda \\theta_{t-1} \\right)}$$\n",
    "\n",
    "### **Optimizer Comparison**\n",
    "\n",
    "| Optimizer | Pros | Cons | Best For |\n",
    "|-----------|------|------|----------|\n",
    "| **SGD** | Simple, well-understood | Slow convergence | Convex problems |\n",
    "| **SGD + Momentum** | Faster convergence | Hyperparameter tuning | General use |\n",
    "| **AdaGrad** | Adaptive learning rate | Learning rate decay | Sparse data |\n",
    "| **RMSprop** | Fixes AdaGrad issues | Still needs tuning | RNNs |\n",
    "| **Adam** | Fast, adaptive, robust | May not converge | Most problems |\n",
    "| **AdamW** | Better generalization | More complex | Deep learning |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **Gradient Descent in Neural Networks**\n",
    "\n",
    "### **Backpropagation**\n",
    "\n",
    "In neural networks, gradients are computed using the **chain rule**:\n",
    "\n",
    "$$\\boxed{\\frac{\\partial J}{\\partial w_{ij}^{(l)}} = \\frac{\\partial J}{\\partial a_j^{(l)}} \\frac{\\partial a_j^{(l)}}{\\partial z_j^{(l)}} \\frac{\\partial z_j^{(l)}}{\\partial w_{ij}^{(l)}}}$$\n",
    "\n",
    "Where:\n",
    "- $w_{ij}^{(l)}$ is weight from neuron $i$ in layer $l-1$ to neuron $j$ in layer $l$\n",
    "- $a_j^{(l)}$ is activation of neuron $j$ in layer $l$\n",
    "- $z_j^{(l)}$ is pre-activation of neuron $j$ in layer $l$\n",
    "\n",
    "### **Forward Pass**\n",
    "\n",
    "$$\\boxed{\\begin{align}\n",
    "z^{(l)} &= W^{(l)} a^{(l-1)} + b^{(l)} \\\\\n",
    "a^{(l)} &= \\sigma(z^{(l)})\n",
    "\\end{align}}$$\n",
    "\n",
    "### **Backward Pass**\n",
    "\n",
    "For output layer:\n",
    "$$\\boxed{\\delta^{(L)} = \\nabla_a J \\odot \\sigma'(z^{(L)})}$$\n",
    "\n",
    "For hidden layers:\n",
    "$$\\boxed{\\delta^{(l)} = ((W^{(l+1)})^T \\delta^{(l+1)}) \\odot \\sigma'(z^{(l)})}$$\n",
    "\n",
    "Weight updates:\n",
    "$$\\boxed{\\frac{\\partial J}{\\partial W^{(l)}} = \\delta^{(l)} (a^{(l-1)})^T}$$\n",
    "\n",
    "$$\\boxed{\\frac{\\partial J}{\\partial b^{(l)}} = \\delta^{(l)}}$$\n",
    "\n",
    "### **Gradient Clipping**\n",
    "\n",
    "Prevents **exploding gradients**:\n",
    "\n",
    "$$\\boxed{\\nabla \\theta = \\begin{cases}\n",
    "\\nabla \\theta & \\text{if } \\|\\nabla \\theta\\| \\leq c \\\\\n",
    "\\frac{c}{\\|\\nabla \\theta\\|} \\nabla \\theta & \\text{if } \\|\\nabla \\theta\\| > c\n",
    "\\end{cases}}$$\n",
    "\n",
    "---\n",
    "\n",
    "## üíª **Practical Implementation**\n",
    "\n",
    "### **NumPy Implementation**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def gradient_descent(X, y, learning_rate=0.01, epochs=1000):\n",
    "    \"\"\"\n",
    "    Simple gradient descent for linear regression\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "    cost_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        predictions = X.dot(theta)\n",
    "        \n",
    "        # Compute cost\n",
    "        cost = (1/(2*m)) * np.sum((predictions - y)**2)\n",
    "        cost_history.append(cost)\n",
    "        \n",
    "        # Compute gradients\n",
    "        gradients = (1/m) * X.T.dot(predictions - y)\n",
    "        \n",
    "        # Update parameters\n",
    "        theta -= learning_rate * gradients\n",
    "        \n",
    "        # Print progress\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Cost: {cost:.4f}\")\n",
    "    \n",
    "    return theta, cost_history\n",
    "```\n",
    "\n",
    "### **Mini-Batch Implementation**\n",
    "\n",
    "```python\n",
    "def mini_batch_gradient_descent(X, y, batch_size=32, learning_rate=0.01, epochs=1000):\n",
    "    \"\"\"\n",
    "    Mini-batch gradient descent\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "    cost_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle data\n",
    "        indices = np.random.permutation(m)\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "        \n",
    "        epoch_cost = 0\n",
    "        num_batches = m // batch_size\n",
    "        \n",
    "        for i in range(0, m, batch_size):\n",
    "            # Get mini-batch\n",
    "            X_batch = X_shuffled[i:i+batch_size]\n",
    "            y_batch = y_shuffled[i:i+batch_size]\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = X_batch.dot(theta)\n",
    "            \n",
    "            # Compute cost\n",
    "            batch_cost = (1/(2*len(X_batch))) * np.sum((predictions - y_batch)**2)\n",
    "            epoch_cost += batch_cost\n",
    "            \n",
    "            # Compute gradients\n",
    "            gradients = (1/len(X_batch)) * X_batch.T.dot(predictions - y_batch)\n",
    "            \n",
    "            # Update parameters\n",
    "            theta -= learning_rate * gradients\n",
    "        \n",
    "        cost_history.append(epoch_cost / num_batches)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Cost: {epoch_cost/num_batches:.4f}\")\n",
    "    \n",
    "    return theta, cost_history\n",
    "```\n",
    "\n",
    "### **Adam Optimizer Implementation**\n",
    "\n",
    "```python\n",
    "class AdamOptimizer:\n",
    "    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.lr = learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        self.t = 0\n",
    "    \n",
    "    def update(self, params, gradients):\n",
    "        if self.m is None:\n",
    "            self.m = np.zeros_like(params)\n",
    "            self.v = np.zeros_like(params)\n",
    "        \n",
    "        self.t += 1\n",
    "        \n",
    "        # Update biased first moment estimate\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * gradients\n",
    "        \n",
    "        # Update biased second moment estimate\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * (gradients ** 2)\n",
    "        \n",
    "        # Compute bias-corrected moments\n",
    "        m_hat = self.m / (1 - self.beta1 ** self.t)\n",
    "        v_hat = self.v / (1 - self.beta2 ** self.t)\n",
    "        \n",
    "        # Update parameters\n",
    "        params -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "        \n",
    "        return params\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è **Common Challenges & Solutions**\n",
    "\n",
    "### **1. Vanishing Gradients**\n",
    "\n",
    "**Problem:** Gradients become very small in deep networks\n",
    "\n",
    "**Solutions:**\n",
    "- üîß **Better activation functions** (ReLU, Leaky ReLU, ELU)\n",
    "- üîß **Proper weight initialization** (Xavier, He initialization)\n",
    "- üîß **Batch normalization**\n",
    "- üîß **Residual connections** (ResNet)\n",
    "- üîß **LSTM/GRU** for RNNs\n",
    "\n",
    "### **2. Exploding Gradients**\n",
    "\n",
    "**Problem:** Gradients become very large\n",
    "\n",
    "**Solutions:**\n",
    "- üîß **Gradient clipping**\n",
    "- üîß **Proper weight initialization**\n",
    "- üîß **Lower learning rates**\n",
    "- üîß **Batch normalization**\n",
    "\n",
    "### **3. Saddle Points**\n",
    "\n",
    "**Problem:** Getting stuck at saddle points\n",
    "\n",
    "**Solutions:**\n",
    "- üîß **Momentum-based optimizers**\n",
    "- üîß **Adding noise** (SGD noise)\n",
    "- üîß **Second-order methods**\n",
    "\n",
    "### **4. Local Minima**\n",
    "\n",
    "**Problem:** Converging to suboptimal solutions\n",
    "\n",
    "**Solutions:**\n",
    "- üîß **Multiple random initializations**\n",
    "- üîß **Simulated annealing**\n",
    "- üîß **Ensemble methods**\n",
    "- üîß **Advanced optimizers** (Adam, RMSprop)\n",
    "\n",
    "### **5. Slow Convergence**\n",
    "\n",
    "**Problem:** Taking too long to converge\n",
    "\n",
    "**Solutions:**\n",
    "- üîß **Learning rate scheduling**\n",
    "- üîß **Adaptive optimizers**\n",
    "- üîß **Feature scaling/normalization**\n",
    "- üîß **Better architectures**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **Applications & Examples**\n",
    "\n",
    "### **1. Linear Regression**\n",
    "\n",
    "**Cost Function:**\n",
    "$$J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "**Gradient:**\n",
    "$$\\nabla J(\\theta) = \\frac{1}{m} X^T (X\\theta - y)$$\n",
    "\n",
    "### **2. Logistic Regression**\n",
    "\n",
    "**Cost Function:**\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(h_\\theta(x^{(i)})) + (1-y^{(i)}) \\log(1-h_\\theta(x^{(i)}))]$$\n",
    "\n",
    "**Gradient:**\n",
    "$$\\nabla J(\\theta) = \\frac{1}{m} X^T (h_\\theta(X) - y)$$\n",
    "\n",
    "### **3. Neural Networks**\n",
    "\n",
    "**Cost Function (Cross-entropy):**\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\sum_{k=1}^{K} y_k^{(i)} \\log(h_\\theta(x^{(i)})_k)$$\n",
    "\n",
    "**Gradients computed via backpropagation**\n",
    "\n",
    "### **4. Support Vector Machines**\n",
    "\n",
    "**Hinge Loss:**\n",
    "$$J(\\theta) = \\frac{1}{2}\\|\\theta\\|^2 + C \\sum_{i=1}^{m} \\max(0, 1 - y^{(i)}(\\theta^T x^{(i)}))$$\n",
    "\n",
    "### **5. Matrix Factorization**\n",
    "\n",
    "**Cost Function:**\n",
    "$$J = \\sum_{(i,j) \\in \\Omega} (r_{ij} - u_i^T v_j)^2 + \\lambda(\\|u_i\\|^2 + \\|v_j\\|^2)$$\n",
    "\n",
    "---\n",
    "\n",
    "## üèÜ **Best Practices**\n",
    "\n",
    "### **1. Data Preprocessing**\n",
    "\n",
    "- üìä **Feature scaling:** Normalize features to similar ranges\n",
    "- üìä **Mean centering:** Subtract mean from features\n",
    "- üìä **Standardization:** $(x - \\mu) / \\sigma$\n",
    "- üìä **Min-Max scaling:** $(x - x_{min}) / (x_{max} - x_{min})$\n",
    "\n",
    "### **2. Hyperparameter Tuning**\n",
    "\n",
    "- üéõÔ∏è **Learning rate:** Start with 0.001, 0.01, 0.1\n",
    "- üéõÔ∏è **Batch size:** Powers of 2 (32, 64, 128, 256)\n",
    "- üéõÔ∏è **Epochs:** Monitor validation loss\n",
    "- üéõÔ∏è **Regularization:** L1/L2 regularization parameters\n",
    "\n",
    "### **3. Monitoring & Debugging**\n",
    "\n",
    "- üìà **Plot cost function** over time\n",
    "- üìà **Monitor gradient norms**\n",
    "- üìà **Check for overfitting** (validation vs training loss)\n",
    "- üìà **Visualize parameter updates**\n",
    "\n",
    "### **4. Initialization Strategies**\n",
    "\n",
    "#### **Xavier/Glorot Initialization**\n",
    "$$W \\sim \\mathcal{N}\\left(0, \\frac{2}{n_{in} + n_{out}}\\right)$$\n",
    "\n",
    "#### **He Initialization**\n",
    "$$W \\sim \\mathcal{N}\\left(0, \\frac{2}{n_{in}}\\right)$$\n",
    "\n",
    "### **5. Regularization Techniques**\n",
    "\n",
    "#### **L1 Regularization (Lasso)**\n",
    "$$J(\\theta) = J_0(\\theta) + \\lambda \\sum_{i=1}^{n} |\\theta_i|$$\n",
    "\n",
    "#### **L2 Regularization (Ridge)**\n",
    "$$J(\\theta) = J_0(\\theta) + \\lambda \\sum_{i=1}^{n} \\theta_i^2$$\n",
    "\n",
    "#### **Dropout**\n",
    "Randomly set neurons to zero during training\n",
    "\n",
    "### **6. Early Stopping**\n",
    "\n",
    "Stop training when validation loss stops improving:\n",
    "\n",
    "```python\n",
    "def early_stopping(val_losses, patience=5, delta=1e-4):\n",
    "    if len(val_losses) < patience + 1:\n",
    "        return False\n",
    "    \n",
    "    recent_losses = val_losses[-patience-1:]\n",
    "    return all(recent_losses[i] - recent_losses[i+1] < delta \n",
    "              for i in range(len(recent_losses)-1))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üéì **Summary**\n",
    "\n",
    "Gradient descent is the **foundation** of modern machine learning optimization. Key takeaways:\n",
    "\n",
    "1. **Core Principle:** Move in the direction opposite to the gradient\n",
    "2. **Types:** Batch, Stochastic, Mini-batch each have trade-offs\n",
    "3. **Learning Rate:** Critical hyperparameter affecting convergence\n",
    "4. **Advanced Optimizers:** Adam, RMSprop often work better than vanilla SGD\n",
    "5. **Challenges:** Vanishing/exploding gradients, local minima, saddle points\n",
    "6. **Best Practices:** Proper preprocessing, initialization, and monitoring\n",
    "\n",
    "### **Formula Cheat Sheet**\n",
    "\n",
    "| Concept | Formula |\n",
    "|---------|---------|\n",
    "| **Basic Update** | $\\theta := \\theta - \\alpha \\nabla J(\\theta)$ |\n",
    "| **Momentum** | $v_t = \\beta v_{t-1} + \\alpha \\nabla J(\\theta)$ |\n",
    "| **Adam** | $\\theta_t = \\theta_{t-1} - \\frac{\\alpha}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t$ |\n",
    "| **Learning Rate Decay** | $\\alpha_t = \\frac{\\alpha_0}{1 + \\text{decay} \\times t}$ |\n",
    "| **Gradient Clipping** | $\\nabla \\theta = \\min(c, \\|\\nabla \\theta\\|) \\frac{\\nabla \\theta}{\\|\\nabla \\theta\\|}$ |\n",
    "\n",
    "---\n",
    "\n",
    "*Happy optimizing! üöÄ*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be7c14c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
