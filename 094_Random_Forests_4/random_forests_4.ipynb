{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4adf26e5",
   "metadata": {},
   "source": [
    "# Random Forest Hyperparameters üéõÔ∏è\n",
    "\n",
    "## Core Tree Parameters üå≥\n",
    "\n",
    "### **n_estimators** \n",
    "**Number of decision trees in the forest**\n",
    "\n",
    "| Parameter | Default | Range | Impact |\n",
    "|-----------|---------|-------|--------|\n",
    "| **Value** | 100 | 10-2000+ | More trees = better performance but slower |\n",
    "\n",
    "$$\\text{Performance} \\propto \\log(\\text{n\\_estimators})$$\n",
    "\n",
    "- **Low values (10-50)**: Fast but may underfit\n",
    "- **High values (500-1000+)**: Better performance, diminishing returns\n",
    "- **Sweet spot**: 100-500 for most problems\n",
    "\n",
    "---\n",
    "\n",
    "### **max_features** \n",
    "**Number of features considered for each split**\n",
    "\n",
    "| Option | Formula | Best For | Mathematical Expression |\n",
    "|--------|---------|----------|------------------------|\n",
    "| `'sqrt'` | $\\sqrt{p}$ | **Classification** | $m = \\sqrt{p}$ |\n",
    "| `'log2'` | $\\log_2(p)$ | High-dimensional data | $m = \\log_2(p)$ |\n",
    "| `None` | $p$ | Small datasets | $m = p$ |\n",
    "| `int` | Custom | Fine-tuning | $m = \\text{specified}$ |\n",
    "| `float` | $p \\times \\text{fraction}$ | Proportional control | $m = \\lfloor p \\times f \\rfloor$ |\n",
    "\n",
    "**Default**: \n",
    "- **Classifier**: `'sqrt'` \n",
    "- **Regressor**: `None` (uses all features)\n",
    "\n",
    "---\n",
    "\n",
    "### **max_depth**\n",
    "**Maximum depth of individual trees**\n",
    "\n",
    "$$\\text{Depth} = \\max\\{\\text{path from root to leaf}\\}$$\n",
    "\n",
    "| Setting | Value | Effect | Use Case |\n",
    "|---------|-------|--------|----------|\n",
    "| **None** | ‚àû | Trees grow until pure/min_samples | Default, good starting point |\n",
    "| **Shallow** | 3-10 | Prevents overfitting | Small datasets, noisy data |\n",
    "| **Deep** | 15-30 | More complex patterns | Large, clean datasets |\n",
    "\n",
    "**Relationship**: $\\text{Max nodes} \\leq 2^{\\text{max\\_depth}} - 1$\n",
    "\n",
    "---\n",
    "\n",
    "## Node Splitting Controls üéØ\n",
    "\n",
    "### **min_samples_split**\n",
    "**Minimum samples required to split an internal node**\n",
    "\n",
    "$$\\text{Split occurs only if } |S_{\\text{node}}| \\geq \\text{min\\_samples\\_split}$$\n",
    "\n",
    "| Value | Type | Effect | Best For |\n",
    "|-------|------|--------|----------|\n",
    "| **2** | Default | Maximum splitting | Large datasets |\n",
    "| **5-20** | Conservative | Reduces overfitting | Medium datasets |\n",
    "| **0.01-0.1** | Fraction | Proportional to dataset size | Variable dataset sizes |\n",
    "\n",
    "---\n",
    "\n",
    "### **min_samples_leaf**\n",
    "**Minimum samples required in each leaf node**\n",
    "\n",
    "$$\\forall \\text{ leaf } L: |L| \\geq \\text{min\\_samples\\_leaf}$$\n",
    "\n",
    "| Value | Effect | Trade-off |\n",
    "|-------|--------|-----------|\n",
    "| **1** | Maximum granularity | May overfit |\n",
    "| **5-50** | Smoother decision boundaries | Better generalization |\n",
    "| **Fraction** | Dataset-proportional | Adaptive to data size |\n",
    "\n",
    "---\n",
    "\n",
    "### **min_weight_fraction_leaf**\n",
    "**Minimum weighted fraction of samples in leaf**\n",
    "\n",
    "$$\\sum_{i \\in \\text{leaf}} w_i \\geq \\text{min\\_weight\\_fraction\\_leaf} \\times \\sum_{i=1}^{n} w_i$$\n",
    "\n",
    "- **Range**: [0.0, 0.5]\n",
    "- **Use**: When samples have different importance weights\n",
    "\n",
    "---\n",
    "\n",
    "## Tree Structure Controls üèóÔ∏è\n",
    "\n",
    "### **max_leaf_nodes**\n",
    "**Maximum number of leaf nodes per tree**\n",
    "\n",
    "$$|\\{L : L \\text{ is leaf}\\}| \\leq \\text{max\\_leaf\\_nodes}$$\n",
    "\n",
    "- **None**: No limit\n",
    "- **Integer**: Explicit constraint\n",
    "- **Effect**: Controls tree complexity directly\n",
    "\n",
    "---\n",
    "\n",
    "### **min_impurity_decrease**\n",
    "**Minimum impurity decrease required for split**\n",
    "\n",
    "$$\\Delta I = I_{\\text{parent}} - \\frac{|S_L|}{|S|} I_L - \\frac{|S_R|}{|S|} I_R \\geq \\text{threshold}$$\n",
    "\n",
    "Where:\n",
    "- $I$ = impurity measure (Gini/Entropy)\n",
    "- $S_L, S_R$ = left and right child samples\n",
    "\n",
    "---\n",
    "\n",
    "## Randomness & Sampling üé≤\n",
    "\n",
    "### **bootstrap**\n",
    "**Whether to use bootstrap sampling**\n",
    "\n",
    "| Setting | Sampling Method | Effect |\n",
    "|---------|----------------|--------|\n",
    "| **True** | With replacement | Standard Random Forest |\n",
    "| **False** | Without replacement | Each tree sees all data |\n",
    "\n",
    "$$\\text{Bootstrap sample size} = n \\text{ (with replacement)}$$\n",
    "\n",
    "**OOB Error** only available when `bootstrap=True`\n",
    "\n",
    "---\n",
    "\n",
    "### **random_state**\n",
    "**Controls randomness for reproducibility**\n",
    "\n",
    "- **None**: Different results each run\n",
    "- **Integer**: Fixed seed for reproducible results\n",
    "- **Critical for**: Model comparison, debugging, production\n",
    "\n",
    "---\n",
    "\n",
    "### **oob_score**\n",
    "**Whether to calculate Out-of-Bag score**\n",
    "\n",
    "$$\\text{OOB Score} = 1 - \\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}[y_i \\neq \\hat{y}_i^{\\text{OOB}}]$$\n",
    "\n",
    "- **Requires**: `bootstrap=True`\n",
    "- **Benefit**: No need for validation set\n",
    "- **Access via**: `model.oob_score_`\n",
    "\n",
    "---\n",
    "\n",
    "## Performance & Efficiency ‚ö°\n",
    "\n",
    "### **n_jobs**\n",
    "**Number of parallel jobs**\n",
    "\n",
    "| Value | Meaning | Performance |\n",
    "|-------|---------|-------------|\n",
    "| **None/1** | Sequential | Slower but less memory |\n",
    "| **-1** | All CPUs | Maximum speed |\n",
    "| **Integer** | Specific CPU count | Balanced approach |\n",
    "\n",
    "**Parallelization**: Trees are independent ‚Üí perfect parallelization\n",
    "\n",
    "---\n",
    "\n",
    "### **verbose**\n",
    "**Verbosity level during fitting**\n",
    "\n",
    "- **0**: Silent\n",
    "- **1**: Progress for each tree (if `n_jobs=1`)\n",
    "- **2+**: More detailed output\n",
    "\n",
    "---\n",
    "\n",
    "## Classification-Specific üìä\n",
    "\n",
    "### **criterion**\n",
    "**Function to measure split quality**\n",
    "\n",
    "| Criterion | Formula | Use Case |\n",
    "|-----------|---------|----------|\n",
    "| **'gini'** | $1 - \\sum_{i=1}^{c} p_i^2$ | Default, faster |\n",
    "| **'entropy'** | $-\\sum_{i=1}^{c} p_i \\log_2(p_i)$ | Information gain |\n",
    "| **'log_loss'** | Logistic loss | Probability estimates |\n",
    "\n",
    "---\n",
    "\n",
    "### **class_weight**\n",
    "**Weights for imbalanced classes**\n",
    "\n",
    "| Option | Effect | Formula |\n",
    "|--------|--------|---------|\n",
    "| **None** | Equal weights | $w_i = 1$ |\n",
    "| **'balanced'** | Inverse frequency | $w_i = \\frac{n}{n_{\\text{classes}} \\times n_i}$ |\n",
    "| **Dict** | Custom weights | User-defined |\n",
    "\n",
    "---\n",
    "\n",
    "## Regression-Specific üìà\n",
    "\n",
    "### **criterion**\n",
    "**Function to measure split quality**\n",
    "\n",
    "| Criterion | Formula | Characteristics |\n",
    "|-----------|---------|----------------|\n",
    "| **'squared_error'** | $\\sum (y - \\bar{y})^2$ | Standard MSE |\n",
    "| **'absolute_error'** | $\\sum |y - \\text{median}(y)|$ | Robust to outliers |\n",
    "| **'friedman_mse'** | Modified MSE | Faster convergence |\n",
    "| **'poisson'** | Poisson deviance | Count data |\n",
    "\n",
    "$$\\text{Friedman MSE} = \\text{MSE} - \\frac{(\\sum y)^2}{n}$$\n",
    "\n",
    "---\n",
    "\n",
    "## Hyperparameter Tuning Strategy üéØ\n",
    "\n",
    "### **Priority Order** (High to Low Impact)\n",
    "\n",
    "1. **n_estimators** ‚Üí Start with 100, increase until performance plateaus\n",
    "2. **max_features** ‚Üí Try `'sqrt'`, `'log2'`, `None`\n",
    "3. **max_depth** ‚Üí Try `None`, then 10, 20, 30\n",
    "4. **min_samples_split** ‚Üí Try 2, 5, 10, 20\n",
    "5. **min_samples_leaf** ‚Üí Try 1, 2, 5, 10\n",
    "\n",
    "### **Grid Search Template**\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "```\n",
    "\n",
    "### **Quick Tuning Rules** üìù\n",
    "\n",
    "| If your model is... | Adjust these parameters |\n",
    "|-------------------|------------------------|\n",
    "| **Overfitting** | ‚Üì `max_depth`, ‚Üë `min_samples_split/leaf` |\n",
    "| **Underfitting** | ‚Üë `n_estimators`, ‚Üì `max_features` |\n",
    "| **Too slow** | ‚Üì `n_estimators`, ‚Üë `max_depth` limit |\n",
    "| **Memory issues** | ‚Üì `n_estimators`, ‚Üë `min_samples_leaf` |\n",
    "\n",
    "---\n",
    "\n",
    "## Advanced Tips üöÄ\n",
    "\n",
    "### **Feature Engineering Integration**\n",
    "- Use **`max_features='sqrt'`** with many irrelevant features\n",
    "- Use **`max_features=None`** with pre-selected features\n",
    "- Consider **feature importance** for recursive feature elimination\n",
    "\n",
    "### **Validation Strategy**\n",
    "- Use **OOB score** for quick validation (`oob_score=True`)\n",
    "- Combine with **cross-validation** for robust estimates\n",
    "- Monitor **learning curves** to detect overfitting\n",
    "\n",
    "### **Production Considerations**\n",
    "- Set **`random_state`** for reproducible models\n",
    "- Use **`n_jobs=-1`** for training, `n_jobs=1` for prediction\n",
    "- Consider **model size** vs **prediction speed** trade-offs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561aa574",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
