{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdae7476",
   "metadata": {},
   "source": [
    "# ðŸ—³ï¸ Voting Ensemble in Regression\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ **What is it?**\n",
    "A regression ensemble method that combines predictions from multiple base regressors by averaging their outputs. Unlike classification voting, regression voting uses **simple averaging** or **weighted averaging** of continuous predictions.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š **How Voting Works in Regression**\n",
    "\n",
    "### ðŸŽ¯ **Simple Averaging (Uniform Voting)**\n",
    "> All models contribute equally to final prediction\n",
    "\n",
    "$$\\hat{y}_{\\text{ensemble}} = \\frac{1}{n} \\sum_{i=1}^{n} \\hat{y}_i$$\n",
    "\n",
    "Where:\n",
    "- $n$ = number of base models\n",
    "- $\\hat{y}_i$ = prediction from model $i$\n",
    "\n",
    "### âš–ï¸ **Weighted Averaging**\n",
    "> Models contribute based on their performance weights\n",
    "\n",
    "$$\\hat{y}_{\\text{ensemble}} = \\frac{\\sum_{i=1}^{n} w_i \\cdot \\hat{y}_i}{\\sum_{i=1}^{n} w_i}$$\n",
    "\n",
    "Where:\n",
    "- $w_i$ = weight for model $i$\n",
    "- $\\sum_{i=1}^{n} w_i = 1$ (normalized weights)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§® **Weight Calculation Strategies**\n",
    "\n",
    "### ðŸ“ˆ **Performance-Based Weights**\n",
    "\n",
    "**1. Inverse MSE Weighting:**\n",
    "$$w_i = \\frac{1/\\text{MSE}_i}{\\sum_{j=1}^{n} 1/\\text{MSE}_j}$$\n",
    "\n",
    "**2. RÂ² Score Weighting:**\n",
    "$$w_i = \\frac{\\text{RÂ²}_i}{\\sum_{j=1}^{n} \\text{RÂ²}_j}$$\n",
    "\n",
    "**3. Inverse RMSE Weighting:**\n",
    "$$w_i = \\frac{1/\\text{RMSE}_i}{\\sum_{j=1}^{n} 1/\\text{RMSE}_j}$$\n",
    "\n",
    "### ðŸŽ² **Cross-Validation Based Weights**\n",
    "```python\n",
    "# Pseudo-code for CV-based weighting\n",
    "for model_i in models:\n",
    "    cv_scores = cross_val_score(model_i, X_train, y_train, cv=5, \n",
    "                               scoring='neg_mean_squared_error')\n",
    "    weights[i] = 1 / (-cv_scores.mean())  # Lower MSE = higher weight\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ—ï¸ **Implementation Types**\n",
    "\n",
    "### ðŸ”§ **VotingRegressor (Sklearn)**\n",
    "> Built-in implementation with simple averaging\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Create base models\n",
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "gb = GradientBoostingRegressor(n_estimators=100)\n",
    "\n",
    "# Voting ensemble\n",
    "voting_reg = VotingRegressor([\n",
    "    ('linear', lr),\n",
    "    ('forest', rf), \n",
    "    ('boosting', gb)\n",
    "])\n",
    "```\n",
    "\n",
    "### ðŸŽ¨ **Custom Weighted Voting**\n",
    "> Manual implementation with custom weights\n",
    "\n",
    "```python\n",
    "class WeightedVotingRegressor:\n",
    "    def __init__(self, models, weights=None):\n",
    "        self.models = models\n",
    "        self.weights = weights or [1/len(models)] * len(models)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for model in self.models:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = np.array([model.predict(X) for model in self.models])\n",
    "        return np.average(predictions, axis=0, weights=self.weights)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š **Mathematical Properties**\n",
    "\n",
    "### ðŸŽ¯ **Bias-Variance Decomposition**\n",
    "\n",
    "For ensemble of $n$ models with individual bias $B_i$ and variance $V_i$:\n",
    "\n",
    "**Ensemble Bias:**\n",
    "$$\\text{Bias}^2_{\\text{ensemble}} = \\left(\\frac{1}{n}\\sum_{i=1}^{n} B_i\\right)^2$$\n",
    "\n",
    "**Ensemble Variance (uncorrelated models):**\n",
    "$$\\text{Var}_{\\text{ensemble}} = \\frac{1}{n^2}\\sum_{i=1}^{n} V_i$$\n",
    "\n",
    "**Ensemble Variance (correlated models):**\n",
    "$$\\text{Var}_{\\text{ensemble}} = \\rho \\sigma^2 + \\frac{1-\\rho}{n}\\sigma^2$$\n",
    "\n",
    "Where $\\rho$ = average correlation, $\\sigma^2$ = average variance\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… **Advantages**\n",
    "\n",
    "```\n",
    "âœ“ Simple and intuitive approach\n",
    "âœ“ Reduces variance without increasing bias\n",
    "âœ“ Works well with diverse, uncorrelated models\n",
    "âœ“ Less prone to overfitting than individual models\n",
    "âœ“ Easy to implement and understand\n",
    "âœ“ Computationally efficient (parallel training)\n",
    "âœ“ Robust to outliers in individual predictions\n",
    "```\n",
    "\n",
    "## âŒ **Disadvantages**\n",
    "\n",
    "```\n",
    "âœ— Limited improvement if models are highly correlated\n",
    "âœ— Poor models can drag down ensemble performance\n",
    "âœ— No learning of optimal combination weights\n",
    "âœ— Requires storage and prediction from all models\n",
    "âœ— May not capture complex model interactions\n",
    "âœ— Performance bounded by best individual model\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽª **Use Cases & Applications**\n",
    "\n",
    "### ðŸ  **Real Estate Price Prediction**\n",
    "```python\n",
    "# Combine different approaches\n",
    "models = [\n",
    "    ('location_model', LinearRegression()),      # Linear relationships\n",
    "    ('feature_model', RandomForestRegressor()),  # Non-linear features  \n",
    "    ('trend_model', GradientBoostingRegressor()) # Temporal patterns\n",
    "]\n",
    "```\n",
    "\n",
    "### ðŸ“ˆ **Financial Forecasting**\n",
    "```python\n",
    "# Different time horizons and approaches\n",
    "models = [\n",
    "    ('technical', SVR()),                    # Technical indicators\n",
    "    ('fundamental', LinearRegression()),     # Economic fundamentals\n",
    "    ('sentiment', RandomForestRegressor())   # Market sentiment\n",
    "]\n",
    "```\n",
    "\n",
    "### ðŸŒ¡ï¸ **Environmental Modeling**\n",
    "```python\n",
    "# Different physical models\n",
    "models = [\n",
    "    ('statistical', Ridge()),               # Statistical patterns\n",
    "    ('physical', DecisionTreeRegressor()),  # Rule-based physics\n",
    "    ('hybrid', XGBRegressor())             # Machine learning\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ› ï¸ **Best Practices**\n",
    "\n",
    "### ðŸŽ¯ **Model Selection Strategy**\n",
    "\n",
    "| Model Type | Strength | Best Used For |\n",
    "|------------|----------|---------------|\n",
    "| **Linear Models** | Simple relationships | Baseline, interpretability |\n",
    "| **Tree-based** | Non-linear patterns | Feature interactions |\n",
    "| **Neural Networks** | Complex patterns | High-dimensional data |\n",
    "| **SVR** | Robust to outliers | Noisy data |\n",
    "\n",
    "### ðŸ“Š **Diversity Maximization**\n",
    "- **Different algorithms**: Linear, tree-based, neural\n",
    "- **Different features**: Subsets, transformations\n",
    "- **Different data**: Bootstrap samples, cross-validation folds\n",
    "- **Different hyperparameters**: Various complexity levels\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ˆ **Performance Evaluation**\n",
    "\n",
    "### ðŸŽ¯ **Ensemble vs Individual Models**\n",
    "\n",
    "```python\n",
    "# Evaluation framework\n",
    "def evaluate_ensemble(models, X_test, y_test):\n",
    "    individual_scores = []\n",
    "    predictions = []\n",
    "    \n",
    "    for name, model in models:\n",
    "        pred = model.predict(X_test)\n",
    "        score = r2_score(y_test, pred)\n",
    "        individual_scores.append((name, score))\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Ensemble prediction\n",
    "    ensemble_pred = np.mean(predictions, axis=0)\n",
    "    ensemble_score = r2_score(y_test, ensemble_pred)\n",
    "    \n",
    "    return individual_scores, ensemble_score\n",
    "```\n",
    "\n",
    "### ðŸ“Š **Key Metrics**\n",
    "\n",
    "| Metric | Formula | Interpretation |\n",
    "|--------|---------|----------------|\n",
    "| **RÂ² Score** | $1 - \\frac{SS_{res}}{SS_{tot}}$ | Variance explained |\n",
    "| **RMSE** | $\\sqrt{\\frac{1}{n}\\sum(y_i - \\hat{y_i})^2}$ | Prediction error |\n",
    "| **MAE** | $\\frac{1}{n}\\sum|y_i - \\hat{y_i}|$ | Average absolute error |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’» **Complete Implementation Example**\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('linear', LinearRegression()),\n",
    "    ('forest', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    ('gradient', GradientBoostingRegressor(n_estimators=100, random_state=42)),\n",
    "    ('svr', SVR(kernel='rbf'))\n",
    "]\n",
    "\n",
    "# Create voting ensemble\n",
    "voting_reg = VotingRegressor(base_models)\n",
    "\n",
    "# Train ensemble\n",
    "voting_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = voting_reg.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"Ensemble RÂ² Score: {r2:.4f}\")\n",
    "print(f\"Ensemble RMSE: {rmse:.4f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ **Advanced Techniques**\n",
    "\n",
    "### ðŸ§  **Dynamic Weighting**\n",
    "Adjust weights based on input characteristics:\n",
    "$$w_i(x) = \\text{softmax}(\\text{NN}(x))_i$$\n",
    "\n",
    "### ðŸ”„ **Stacked Ensemble**\n",
    "Use meta-model to learn optimal combination:\n",
    "$$\\hat{y} = \\text{MetaModel}(\\hat{y_1}, \\hat{y_2}, ..., \\hat{y_n})$$\n",
    "\n",
    "---\n",
    "\n",
    "> **ðŸ’¡ Pro Tip**: Voting works best with diverse, moderately accurate models. Avoid including very poor models as they can hurt overall performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e74f762",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
